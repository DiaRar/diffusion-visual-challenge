[2m2025-12-02T14:45:28.552892Z[0m [32m INFO[0m telemetry disabled [3mmax_workers[0m[2m=[0m32
models/__init__.py:
â‹®...

models/diffusion/__init__.py:
â”‚from .pretrained_diffusion import PretrainedDiffusion
â‹®...

models/diffusion/pretrained_diffusion.py:
â”‚from PIL import Image
â”‚from typing import TYPE_CHECKING
â”‚import gc
â”‚import logging
â”‚import torch
â‹®...
â”‚class PretrainedDiffusion
â‹®...
â”‚def create_pipeline( backbone: str = "sdxl", device: str = "cuda", dtype: torch.dtype = torch.float16, ) -> PretrainedDiffusion
â‹®...

configs/profiles.py:
â”‚from dataclasses import dataclass
â”‚from typing import Final
â‹®...
â”‚@dataclass(frozen=True) @dataclass(frozen=True) class Profile
â”‚    // Profile configuration for inference.
â‹®...
â”‚def get_profile(name: str) -> Profile
â‹®...
â”‚def list_profiles() -> str
â”‚    // List all available profiles with their descriptions.
â‹®...
â”‚def validate_profile(name: str, height: int, width: int) -> bool
â‹®...

infer/generate_image.py:
â”‚from datetime import datetime
â”‚from pathlib import Path
â”‚from typing import TYPE_CHECKING, cast
â”‚import argparse
â”‚import hashlib
â”‚import json
â”‚import logging
â”‚import subprocess
â”‚import sys
â”‚import torch
â‹®...
â”‚def _export_run_metadata( run_id: str, seed: int, prompt: str, profile_name: str, scheduler_mode: str, num_steps: int, backbone: str, out_path: str, negative_prompt: str | None, ) -> Path
â‹®...
â”‚def _generate_run_id(seed: int, prompt: str, profile_name: str) -> str
â”‚    // Generate a unique run ID based on seed, prompt, and profile.
â‹®...
â”‚def _get_git_hash() -> str
â”‚    // Get the current git commit hash.
â‹®...
â”‚def _get_pipeline(backbone: str) -> "DiffusionPipeline"
â‹®...
â”‚def generate_single_image( prompt: str, backbone: str = "sdxl", profile_name: str = "smoke", scheduler_mode: str = "euler", seed: int = 123, out_path: str = "outputs/test.png", num_steps: int | None = None, negative_prompt: str | None = None, ) -> Path
â‹®...
â”‚def main() -> None
â”‚    // Main entry point.
â‹®...
â”‚def parse_args() -> argparse.Namespace
â”‚    // Parse command line arguments.
â‹®...

configs/scheduler_loader.py:
â”‚from typing import TYPE_CHECKING, cast
â”‚import logging
â‹®...
â”‚def apply_scheduler_to_pipeline( pipeline: "DiffusionPipeline", scheduler_name: str, _total_steps: int = 20, # noqa: F841(kept for API compatibility) ) -> tuple["DiffusionPipeline", None]
â‹®...
â”‚def get_scheduler_info(scheduler_name: str) -> dict[str, str] | None
â‹®...
â”‚def list_available_schedulers() -> dict[str, dict[str, str]]
â”‚    // Get all available schedulers information.
â‹®...

